# RQ-VAE配置
data_text_files: "./data/Beauty/item2title.pkl"
text_encoder_model: "/home/lz/code/model/sentence-t5-base"
interaction_files: "./data/Beauty/user2item.pkl"
sent_emb_dim: 768
n_codebooks: 3
codebook_size: 256
rq_e_dim: 32
rq_layers: [512, 256, 128]
dropout_prob: 0
loss_type: "mse"
quant_loss_weight: 1.0
commitment_beta: 0.25
rq_kmeans_init: true
kmeans_iters: 10
learning_rate: 0.001
epochs: 20000
batch_size: 1024
log_interval: 10
save_interval: 5000
embedding_strategy: "mean_pooling"
final_model_decision: "save_final"
cf_emb_path: "none"
cf_alpha: 0.01
diversity_beta: 0.01
