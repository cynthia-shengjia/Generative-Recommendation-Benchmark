from typing import Optional, Dict, List  
from functools import partial  
from transformers import TrainingArguments, EarlyStoppingCallback  
from genrec.utils.metrics import compute_metrics  
from genrec.trainers.offline_rl.sdpo_trainer import SDPOTrainer  
from genrec.utils.callbacks.generative.generative_callback import (  
    GenerativeLoggingCallback,  
    EvaluateEveryNEpochsCallback  
)  
from genrec.utils.models_setup.conditional_t5_setup import create_t5_model  

def create_trainer(  
    model,  
    training_args,  
    train_dataset,  
    eval_dataset,  
    data_collator,  
    # é€šç”¨å‚æ•°  
    callbacks: Optional[List] = None,  
    # S-DPO ç‰¹æœ‰å‚æ•°  
    ref_model: Optional = None,  
    beta: float = 0.1,  
    eval_data_collator = None,  
    # ç”Ÿæˆè¯„ä¼°å‚æ•°  
    compute_metrics: Optional[callable] = None,  
    generation_params: Optional[Dict] = None,  
    item2tokens: Optional[Dict] = None,  
    pad_token_id: Optional[int] = None,  
    eos_token_id: Optional[int] = None,  
    **kwargs  
):  
    """  
    åˆ›å»º SDPOTrainer çš„å·¥å‚å‡½æ•°  
      
    Args:  
        model: ç­–ç•¥æ¨¡å‹
        training_args: è®­ç»ƒå‚æ•°
        train_dataset: è®­ç»ƒæ•°æ®é›†ï¼ˆåŒ…å« chosen/rejected labelsï¼‰
        eval_dataset: è¯„ä¼°æ•°æ®é›†ï¼ˆåªéœ€è¦ chosen_labelsï¼‰
        data_collator: è®­ç»ƒæ•°æ® collator
        callbacks: å›è°ƒå‡½æ•°åˆ—è¡¨
        ref_model: å‚è€ƒæ¨¡å‹ï¼ˆç”¨äº S-DPOï¼‰
        beta: S-DPO æ¸©åº¦å‚æ•°
        eval_data_collator: è¯„ä¼°æ•°æ® collator
        compute_metrics: è¯„ä¼°æŒ‡æ ‡è®¡ç®—å‡½æ•°
        generation_params: ç”Ÿæˆå‚æ•°ï¼ˆmax_gen_length, num_beams, max_kï¼‰
        item2tokens: item åˆ° token çš„æ˜ å°„ï¼ˆç”¨äºå‰ç¼€çº¦æŸï¼‰
        pad_token_id: pad token id
        eos_token_id: eos token id
    """  
      
    # æ£€æŸ¥å¿…éœ€å‚æ•°  
    if ref_model is None:  
        raise ValueError("ä½¿ç”¨ SDPOTrainer æ—¶éœ€è¦æä¾› ref_model å‚æ•°")  
    
    if None in [compute_metrics, generation_params, item2tokens, pad_token_id, eos_token_id]:
        raise ValueError("ä½¿ç”¨ SDPOTrainer è¿›è¡Œç”Ÿæˆè¯„ä¼°æ—¶éœ€è¦æä¾› compute_metrics, "
                       "generation_params, item2tokens, pad_token_id å’Œ eos_token_id å‚æ•°")
      
    return SDPOTrainer(  
        model=model,  
        ref_model=ref_model,  
        beta=beta,  
        args=training_args,  
        train_dataset=train_dataset,  
        eval_dataset=eval_dataset,  
        data_collator=data_collator,  
        eval_data_collator=eval_data_collator,  
        callbacks=callbacks,  
        compute_metrics=compute_metrics,  
        generation_params=generation_params,  
        item2tokens=item2tokens,  
        pad_token_id=pad_token_id,  
        eos_token_id=eos_token_id,  
        **kwargs  
    )  

def setup_training(  
    model,   
    tokenizer,   
    train_dataset,   
    valid_dataset,   
    model_config,   
    offline_rl_config,  
    output_dirs,   
    logger,   
    per_device_train_batch_size,  
    per_device_eval_batch_size,   
    train_data_collator,  
    eval_data_collator  
):  
    """
    è®¾ç½® S-DPO è®­ç»ƒ
    
    Args:
        model: ç­–ç•¥æ¨¡å‹
        tokenizer: åˆ†è¯å™¨
        train_dataset: è®­ç»ƒæ•°æ®é›†ï¼ˆåŒ…å« chosen/rejected labelsï¼‰
        valid_dataset: éªŒè¯æ•°æ®é›†ï¼ˆåªéœ€è¦ chosen_labelsï¼Œç”¨äºç”Ÿæˆè¯„ä¼°ï¼‰
        model_config: æ¨¡å‹é…ç½®
        offline_rl_config: ç¦»çº¿å¼ºåŒ–å­¦ä¹ é…ç½®
        output_dirs: è¾“å‡ºç›®å½•
        logger: æ—¥å¿—è®°å½•å™¨
        per_device_train_batch_size: è®­ç»ƒæ‰¹æ¬¡å¤§å°
        per_device_eval_batch_size: è¯„ä¼°æ‰¹æ¬¡å¤§å°
        train_data_collator: è®­ç»ƒæ•°æ® collatorï¼ˆå¤„ç† chosen/rejectedï¼‰
        eval_data_collator: è¯„ä¼°æ•°æ® collatorï¼ˆåªå¤„ç† chosenï¼‰
    """
    
    # ===== 1. è®­ç»ƒå‚æ•°é…ç½® =====
    training_args = TrainingArguments(  
        output_dir=output_dirs['model'],  
        num_train_epochs=model_config['num_epochs'],  
        per_device_train_batch_size=per_device_train_batch_size,  
        per_device_eval_batch_size=per_device_eval_batch_size,  
        learning_rate=model_config['learning_rate'],  
        weight_decay=model_config["weight_decay"],  
        eval_strategy="epoch",  
        save_strategy="epoch",  
        save_total_limit=2,  
        load_best_model_at_end=True,  
        logging_dir=output_dirs['logs'],  
        logging_steps=100,  
        report_to=[],  
        warmup_ratio=model_config["warmup_ratio"],  
        ddp_find_unused_parameters=False,  
        remove_unused_columns=False,  
        # ğŸ”´ è¯„ä¼°æŒ‡æ ‡é…ç½®ï¼ˆä½¿ç”¨ç”Ÿæˆè¯„ä¼°æŒ‡æ ‡ï¼‰
        metric_for_best_model="ndcg@10",  # æˆ– "recall@10"
        greater_is_better=True,  
    )  
    
    # ===== 2. ç”Ÿæˆè¯„ä¼°å‚æ•° =====
    tokens_to_item_map = tokenizer.tokens2item  
    compute_metrics_with_map = partial(
        compute_metrics, 
        tokens_to_item_map=tokens_to_item_map
    )  
      
    num_beams = model_config.get('num_beams', 10)  
    max_gen_length = model_config.get('max_gen_length', 5)  
    k_list = model_config.get('k_list', [5, 10, 20])  
    max_k = k_list[-1] if k_list else 10
      
    generation_params = {  
        'max_gen_length': max_gen_length,  
        'num_beams': num_beams,  
        'max_k': max_k  
    }  
    
    # ===== 3. å›è°ƒå‡½æ•° =====
    callbacks = [  
        EarlyStoppingCallback(
            early_stopping_patience=model_config.get("early_stop_upper_steps", 1000)
        ),   
        GenerativeLoggingCallback(logger),   
        EvaluateEveryNEpochsCallback(
            n_epochs=model_config.get("evaluation_epoch", 5)
        )  
    ]  
    
    # ===== 4. åˆ›å»ºå‚è€ƒæ¨¡å‹ =====
    logger.info("åˆ›å»ºå‚è€ƒæ¨¡å‹ï¼ˆReference Modelï¼‰...")
    ref_model = create_t5_model(  
        vocab_size=tokenizer.vocab_size,  
        model_config=model_config  
    )  
    # ğŸ”´ åŠ è½½ä¸ç­–ç•¥æ¨¡å‹ç›¸åŒçš„æƒé‡  
    ref_model.load_state_dict(model.state_dict())  
    ref_model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    # ğŸ”´ å†»ç»“å‚è€ƒæ¨¡å‹å‚æ•°
    for param in ref_model.parameters():
        param.requires_grad = False
    logger.info("å‚è€ƒæ¨¡å‹åˆ›å»ºå®Œæˆ")
    
    # ===== 5. åˆ›å»º Trainer =====
    trainer = create_trainer(  
        model=model,  
        training_args=training_args,  
        train_dataset=train_dataset,  
        eval_dataset=valid_dataset,  
        data_collator=train_data_collator,  
        eval_data_collator=eval_data_collator,  
        callbacks=callbacks,  
        # S-DPO å‚æ•°  
        ref_model=ref_model,  
        beta=offline_rl_config.get('beta', 0.1),  
        # ç”Ÿæˆè¯„ä¼°å‚æ•°  
        compute_metrics=compute_metrics_with_map,  
        generation_params=generation_params,  
        item2tokens=tokenizer.item2tokens,  
        pad_token_id=tokenizer.pad_token,  
        eos_token_id=tokenizer.eos_token,  
    )  
    
    logger.info(f"Trainer é…ç½®å®Œæˆ:")
    logger.info(f"  - Beta: {offline_rl_config.get('beta', 0.1)}")
    logger.info(f"  - Num beams: {num_beams}")
    logger.info(f"  - Max gen length: {max_gen_length}")
    logger.info(f"  - Max k: {max_k}")
    logger.info(f"  - Metric for best model: {training_args.metric_for_best_model}")
      
    return trainer